---
title: "Data Science II Final Project Analysis"
author: "Camille Okonkwo"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
editor_options: 
  chunk_output_type: console
--- 
\newpage

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(tidymodels)
library(splines)
library(caret)
library(glmnet)
library(table1)
library(kableExtra)
library(summarytools)
library(corrplot)
library(cowplot)

library(vip)
library(pROC)
library(glmnet)
library(tidymodels)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)

library(rpart)
library(rpart.plot)
```
\newpage

# Background

A research study aims to identify key factors that predict the severity of COVID-19 illness. This study collects demographic information, clinical variables, and disease severity among participants infected with COVID-19 between 2021 and 2023. The goal is to develop a robust prediction model that can accurately predict COVID-19 severity and understand how predictors impact the risk of severe infection.

# Data

The training data in "severity_training.RData" includes data from 800 participants.

The test data in "severity_test.RData" includes data from another set of 200 participants.

Here is a description of each variable:

* ID (`id`): Participant ID
* Age (`age`): Age
* Gender (`gender`): 1 = Male, 0 = Female
* Race/ethnicity (`race`): 1 = White, 2 = Asian, 3 = Black, 4 = Hispanic
* Smoking (`smoking`): Smoking status; 0 = Never smoked, 1 = Former smoker, 2 = Current smoker
* Height (`height`): Height (in centimeters)
* Weight (`weight`): Weight (in kilograms)
* BMI (`bmi`): Body Mass Index; BMI = weight (in kilograms) / height (in meters) squared
* Hypertension (`hypertension`): 0 = No, 1 = Yes
* Diabetes (`diabetes`): 0 = No, 1 = Yes
* Systolic blood pressure (`SBP`): Systolic blood pressure (in mm/Hg)
* LDL cholesterol (`LDL`): LDL (low-density lipoprotein) cholesterol (in mg/dL)
* Vaccination status at the time of infection (`vaccine`): 0 = Not vaccinated, 1 = Vaccinated
* Depression score (`depression`): Higher scores indicate higher risk for depression
* Severity of COVID-19 infection (`severity`): **Response variable**; 0 = Not severe,  1 = Severe

## Data Preparation
```{r data_partition, echo = T, message = FALSE, results = 'hide', warning=FALSE}
# loading training data
load("data/severity_training.RData") 

# making discrete variables factors
training_data = training_data |> 
  select(-id) |> 
  mutate_at(vars(age, height, weight, bmi, SBP, LDL, depression), as.numeric) |> 
 mutate(
    gender = factor(gender, 
                    levels = c(0, 1), 
                    labels = c("Female", "Male")) |> 
      relevel(ref = "Female"),
    race = factor(race, 
                  levels = c(1, 2, 3, 4), 
                  labels = c("White", "Asian", "Black", "Hispanic")) |> 
      relevel(ref = "White"),
    smoking = factor(smoking, 
                     levels = c(0, 1, 2), 
                     labels = c("Never_smoked", "Former_smoker", "Current_smoker")) |> 
      relevel(ref = "Never_smoked"),
    hypertension = factor(hypertension, 
                          levels = c(0, 1), 
                          labels = c("No", "Yes")) |> 
      relevel(ref = "No"),
    diabetes = factor(diabetes, 
                      levels = c(0, 1), 
                      labels = c("No", "Yes")) |> 
      relevel(ref = "No"),
    vaccine = factor(vaccine, 
                     levels = c(0, 1), 
                     labels = c("Not_vaccinated", "Vaccinated")) |> 
      relevel(ref = "Not_vaccinated"),
    severity = factor(severity, 
                      levels = c(0, 1), 
                      labels = c("Not_severe", "Severe")) |> 
      relevel(ref = "Not_severe")
  ) |> 
  janitor::clean_names()

# checking levels
levels(training_data$race)
levels(training_data$smoking)
levels(training_data$hypertension)
levels(training_data$diabetes)
levels(training_data$vaccine)
levels(training_data$severity)

# matrix of predictors & vector of response for data set exploration
x.train = model.matrix(severity ~ ., training_data)[, -1]
y.train = training_data$severity

# loading testing data
load("data/severity_test.RData")

# making discrete variables factors
test_data = test_data |> 
  select(-id) |> 
  mutate_at(vars(age, height, weight, bmi, SBP, LDL, depression), as.numeric) |> 
 mutate(
    gender = factor(gender, 
                    levels = c(0, 1), 
                    labels = c("Female", "Male")) |> 
      relevel(ref = "Female"),
    race = factor(race, 
                  levels = c(1, 2, 3, 4), 
                  labels = c("White", "Asian", "Black", "Hispanic")) |> 
      relevel(ref = "White"),
    smoking = factor(smoking, 
                     levels = c(0, 1, 2), 
                     labels = c("Never_smoked", "Former_smoker", "Current_smoker")) |> 
      relevel(ref = "Never_smoked"),
    hypertension = factor(hypertension, 
                          levels = c(0, 1), 
                          labels = c("No", "Yes")) |> 
      relevel(ref = "No"),
    diabetes = factor(diabetes, 
                      levels = c(0, 1), 
                      labels = c("No", "Yes")) |> 
      relevel(ref = "No"),
    vaccine = factor(vaccine, 
                     levels = c(0, 1), 
                     labels = c("Not_vaccinated", "Vaccinated")) |> 
      relevel(ref = "Not_vaccinated"),
    severity = factor(severity, 
                      levels = c(0, 1), 
                      labels = c("Not_severe", "Severe")) |> 
      relevel(ref = "Not_severe")
  ) |> 
  janitor::clean_names()

# matrix of predictors and vector of response
x.test = model.matrix(severity ~., test_data)[, -1]
y.test = test_data$severity
```
\newpage

# Exploratory analysis and data visualization

## Descriptive Statistics of Training Data
```{r}
descriptive_table = table1(~ age + gender + race + smoking + height + weight + bmi + hypertension + diabetes + sbp + ldl + vaccine + depression | severity,
                            data = training_data,
                            overall = "Total",
                            caption = "Descriptive Characteristics of Participants, Stratified by Severity of COVID-19 Infection")

ds = t1kable(descriptive_table)
ds
```

## Continuous Variable Visualization
```{r}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 2
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(
  x.train[, -c(2, 3, 4, 5, 6, 7, 11, 12, 15)],
  y.train,
  scales = list(x = list(relation = "free"),
                y = list(relation = "free")),
  plot = "box")
```

The mean and median ages for both `Severity` groups (Not Severe and Severe) are close, indicating a relatively balanced distribution of age across severity levels. `Height`, `Weight`, and `BMI` have similar mean and median values, suggesting comparable distributions of these variables between the two `severity` groups. The Systolic Blood Pressure (`SBP`) and LDL cholesterol (`LDL`) variables show slightly higher mean values in the Severe group compared to the Not Severe group, indicating potential differences in these clinical measures between `severity` levels.

## Descriptive Table of Discrete Variables
```{r}
descriptive_table2 = table1(~ gender + race + smoking + hypertension + diabetes + vaccine | severity,
                            data = training_data,
                            overall = "Total",
                            caption = "Descriptive Characteristics of Participants, Stratified by Severity of COVID-19 Infection")

ds_bin = t1kable(descriptive_table2)
ds_bin
```

The distribution of `gender` is relatively balanced in both `severity` groups, with slightly more females in the Not Severe group and slightly more males in the Severe group. The majority of participants in both `severity` groups are White, followed by Black, Asian, and Hispanic participants. The distribution across `race` appears to be consistent between severity levels. The majority of participants in both `severity` groups are non-smokers (Never smoked category), followed by former smokers and current smokers. The distribution of `smoking` status is similar between `severity` levels.The prevalence of `hypertension` and `diabetes` is noticeably higher in the Severe group compared to the Not Severe group, indicating a potential association between these conditions and COVID-19 `severity`. A significant proportion of participants in the Severe group are not vaccinated, while the majority in the Not Severe group are vaccinated. This suggests a potential protective effect of vaccination against severe COVID-19 infection. The mean and median `depression` scores are similar between `severity` groups, indicating comparable levels of depression risk or severity across severity levels.
\newpage

# Pre-Processing

Based on the descriptive statistics of the training data, scaling the training data has potential benefits for most of the classificaiton algorithms I plan to use. I will scale the data foe the benefits of standardizing the features, model stability, and ensuring that each feature contributes meaningfully to the model training process.

```{r}
# Preprocess the training data by centering and scaling numerical features
t_train = preProcess(training_data, 
                     method = c("center", "scale"))
t_train

# Apply the preprocessing transformation to the training data to obtain scaled data
scaled_training = predict(t_train, newdata = training_data)

head(scaled_training)

# Create the design matrix for training with scaled features, excluding the intercept column
x.train.scaled = model.matrix(severity ~ ., scaled_training)[, -1]

# Extract the scaled target variable (severity) from the scaled training data
y.train.scaled = scaled_training$severity

# Preprocess the test data using the same transformation applied to the training data
t_test = preProcess(test_data, 
                     method = c("center", "scale"))
t_test

# Apply the preprocessing transformation to the test data to obtain scaled data
scaled_testing = predict(t_test, newdata = test_data)

# Create the design matrix for testing with scaled features, excluding the intercept column
x.test.scaled = model.matrix(severity ~ ., scaled_testing)[, -1]

# Extract the scaled target variable (severity) from the scaled testing data
y.test.scaled = scaled_training$severity
```

I will compare model performance between scaled and un-scaled data to see if there any benefits from scaling.

\newpage

# Model training

## Logistic Regression
```{r}
# setting a 10-fold cross-validation
ctrl = trainControl(method = "cv", number = 10,
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)
set.seed(2)

# logistic regression
model.glm = train(x = x.train,
                   y = y.train,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

plot(model.glm$finalModel)
coef(model.glm$finalModel)

set.seed(2)
# logistic regression scaled
scaled.model.glm = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

plot(scaled.model.glm$finalModel)
coef(scaled.model.glm$finalModel)
```
\newpage

## Penalized Logistic Regression
```{r}
# penalized logistic regression - elastic net
glmnGrid = expand.grid(.alpha = seq(0, 1, length = 21),
                       .lambda = exp(seq(-8, -1, length = 50)))
set.seed(2)
model.glmn = train(x = x.train,
                   y = y.train,
                   method = "glmnet",
                   tuneGrid = glmnGrid,
                   metric = "ROC",
                   trControl = ctrl)
model.glmn$bestTune

myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))

# penalized logistic regression - scaled
set.seed(2)
scaled.model.glmn = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "glmnet",
                   tuneGrid = glmnGrid,
                   metric = "ROC",
                   trControl = ctrl)
scaled.model.glmn$bestTune

myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(scaled.model.glmn, par.settings = myPar, xTrans = function(x) log(x))
```
\newpage

## KNN - how to tune?
```{r}
# KNN
set.seed(2)
model.knn = train(x.train, y.train,
                 method = "knn",
                 trControl = ctrl,
                 tuneGrid = expand.grid(k = seq(from = 1, to = 35, by = 1)))

ggplot(model.knn, highlight = TRUE) + theme_bw()
model.knn$finalModel

# KNN scaled
set.seed(2)
scaled.model.knn = train(x.train.scaled, y.train.scaled,
                 method = "knn",
                 trControl = ctrl,
                 tuneGrid = expand.grid(k = seq(from = 1, to = 35, by = 1)))

ggplot(scaled.model.knn, highlight = TRUE) + theme_bw()
```
\newpage

## PLS
```{r}
set.seed(2)
# pls 
model.pls = train(x.train, y.train,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:13),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(model.pls, highlight = TRUE) + theme_bw()
model.pls$bestTune

set.seed(2)

# pls scaled
scaled.model.pls = train(x.train.scaled, y.train.scaled,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:13),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(scaled.model.pls, highlight = TRUE) + theme_bw()
model.pls$bestTune
```
\newpage

## MARS
```{r}
# MARS 
set.seed(2)
model.mars = train(x = x.train,
                   y = y.train,
                   method = "earth",
                   tuneGrid = expand.grid(degree = 1:4,
                                          nprune = 2:20),
                   metric = "ROC",
                   trControl = ctrl)

ggplot(model.mars, highlight = TRUE)
model.mars$bestTune
coef(model.mars$finalModel)

# MARS scaled
set.seed(2)
scaled.model.mars = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "earth",
                   tuneGrid = expand.grid(degree = 1:4,
                                          nprune = 2:20),
                   metric = "ROC",
                   trControl = ctrl)

ggplot(scaled.model.mars, highlight = TRUE)
scaled.model.mars$bestTune
coef(scaled.model.mars$finalModel)
```
\newpage

##  GAM
```{r}
set.seed(2)

model.gam = train(x = x.train,
                  y = y.train,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

model.gam$finalModel
plot(model.gam$finalModel)
coef(model.gam)

# GAM scaled
set.seed(2)

scaled.model.gam = train(x = x.train.scaled,
                  y = y.train.scaled,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

scaled.model.gam$finalModel
plot(scaled.model.gam$finalModel)
```
\newpage

## LDA 
```{r}
set.seed(2)
model.lda = train(x = x.train,
                   y = y.train,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

model.lda$finalModel
coef(model.lda)

# LDA scaled
set.seed(2)
scaled.model.lda = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

scaled.model.lda$finalModel
```
\newpage

## QDA
```{r}
set.seed(2)
model.qda = train(x = x.train,
                  y = y.train,
                  method = "qda",
                  metric = "ROC",
                  trControl = ctrl)
model.qda$finalModel

coef(model.qda)

# QDA scaled
set.seed(2)
scaled.model.qda = train(x = x.train.scaled,
                  y = y.train.scaled,
                  method = "qda",
                  metric = "ROC",
                  trControl = ctrl)
scaled.model.qda$finalModel
```
\newpage

## Naive Bayes (NB)
```{r} 
nbGrid = expand.grid(usekernel = c(FALSE, TRUE),
                     fL = 1,
                     adjust = seq(.2, 5, by = .2))
set.seed(2)
model.nb = train(x = x.train,
                 y = y.train,
                 method = "nb",
                 tuneGrid = nbGrid,
                 metric = "ROC",
                 trControl = ctrl)
plot(model.nb)

model.nb$bestTune
model.nb$finalModel

# NB scaled

set.seed(2)
scaled.model.nb = train(x = x.train.scaled,
                 y = y.train.scaled,
                 method = "nb",
                 tuneGrid = nbGrid,
                 metric = "ROC",
                 trControl = ctrl)
plot(scaled.model.nb)

scaled.model.nb$bestTune
scaled.model.nb$finalModel
```
\newpage

## CART
```{r}
set.seed(2)
model.cart = train(x = x.train,
                   y = y.train,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-8,-5, len = 100))),
                  trControl = ctrl,
                  metric = "ROC")

plot(model.cart, xTrans = log)

model.cart$bestTune
rpart.plot(model.cart$finalModel)

# CART scaled
set.seed(2)
scaled.model.cart = train(x = x.train.scaled,
                   y = y.train.scaled,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-8,-5, len = 100))),
                  trControl = ctrl,
                  metric = "ROC")

plot(scaled.model.cart, xTrans = log)

scaled.model.cart$bestTune
rpart.plot(scaled.model.cart$finalModel)
```
\newpage

## Conditional Inference Trees (CIT)
```{r}
set.seed(2)

model.cit = train(x = x.train,
                  y = y.train,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1-exp(seq(-8, -1, length = 100))),
                  trControl = ctrl)

ggplot(model.cit, highlight = TRUE)

model.cit$bestTune

plot(model.cit$finalModel)

#CIT scaled
set.seed(2)

scaled.model.cit = train(x = x.train.scaled,
                  y = y.train.scaled,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1-exp(seq(-8, -1, length = 100))),
                  trControl = ctrl)

ggplot(scaled.model.cit, highlight = TRUE)

scaled.model.cit$bestTune

plot(scaled.model.cit$finalModel)
```
\newpage

## Random Forest
```{r}
# Try more if possible
rf.grid = expand.grid(mtry = 1:13,
                      splitrule = "gini",
                      min.node.size = seq(from = 2, to = 16, by = 2))
set.seed(2)
model.rf = train(x = x.train,
                 y = y.train,
                 method = "ranger",
                 tuneGrid = rf.grid,
                 trControl = ctrl)
model.rf$bestTune

ggplot(model.rf, highlight = TRUE)

# RF scaled
set.seed(2)
scaled.model.rf = train(x = x.train.scaled,
                 y = y.train.scaled,
                 method = "ranger",
                 tuneGrid = rf.grid,
                 trControl = ctrl)
scaled.model.rf$bestTune

ggplot(scaled.model.rf, highlight = TRUE)
```
\newpage

## AdaBoost
```{r}
# Try more
gbmA.grid = expand.grid(n.trees = c(1000,2000,3000,4000,5000),
                        interaction.depth = 1:6,
                        shrinkage = c(0.001, 0.002, 0.003),
                        n.minobsinnode = 1)

set.seed(2)

model.gbmA = train(x = x.train,
                 y = y.train,
                 tuneGrid = gbmA.grid,
                 trControl = ctrl,
                 method = "gbm",
                 distribution = "adaboost",
                 metric = "ROC",
                 verbose = FALSE)
model.gbmA$bestTune

ggplot(model.gbmA, highlight = TRUE)

# boosted rf scaled
set.seed(2)

scaled.model.gbmA = train(x = x.train.scaled,
                 y = y.train.scaled,
                 tuneGrid = gbmA.grid,
                 trControl = ctrl,
                 method = "gbm",
                 distribution = "adaboost",
                 metric = "ROC",
                 verbose = FALSE)
scaled.model.gbmA$bestTune

ggplot(scaled.model.gbmA, highlight = TRUE)
```
\newpage

## Support Vector Machine: linear
```{r}
set.seed(2)

model.svml = train(x = x.train,
                   y = y.train,
                   method = "svmLinear",
                   tuneGrid = data.frame(C = exp(seq(-8, 2, len = 50))),
                   trControl = ctrl)

model.svml$bestTune

plot(model.svml, highlight = TRUE, xTrans = log)

# SVM linear scaled
set.seed(2)

scaled.model.svml = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "svmLinear",
                   tuneGrid = data.frame(C = exp(seq(-8, 2, len = 50))),
                   trControl = ctrl)

scaled.model.svml$bestTune

plot(scaled.model.svml, highlight = TRUE, xTrans = log)
```
\newpage

## SVML: e1071
```{r}
set.seed(2)

model.svml2 = train(x = x.train,
                    y = y.train,
                   method = "svmLinear2",
                   tuneGrid = data.frame(cost = exp(seq(-8, 2, len = 50))),
                   trControl = ctrl)

model.svml2$bestTune

plot(model.svml2, highlight = TRUE, xTrans = log)

# SVML e1071 scaled
set.seed(2)

scaled.model.svml2 = train(x = x.train.scaled,
                    y = y.train.scaled,
                   method = "svmLinear2",
                   tuneGrid = data.frame(cost = exp(seq(-8, 2, len = 50))),
                   trControl = ctrl)

scaled.model.svml2$bestTune

plot(scaled.model.svml2, highlight = TRUE, xTrans = log)
```
\newpage

## SVML: Radial Sigma
```{r}
svmr.grid = expand.grid(C = exp(seq(1, 7, len = 50)),
                        sigma = exp(seq(-8, -2, len = 20)))

# tunes over both cost and sigma
set.seed(2)
model.svmr = train(x = x.train,
                   y = y.train,
                   method = "svmRadialSigma",
                   tuneGrid = svmr.grid,
                   trControl = ctrl)

myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))

model.svmr$bestTune

plot(model.svmr, highlight = TRUE, par.settings = myPar)

# scaled model
set.seed(2)
scaled.model.svmr = train(x = x.train.scaled,
                   y = y.train.scaled,
                   method = "svmRadialSigma",
                   tuneGrid = svmr.grid,
                   trControl = ctrl)

myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))

scaled.model.svmr$bestTune

plot(scaled.model.svmr, highlight = TRUE, par.settings = myPar)
```
\newpage

## SVML: radial cost
```{r}
set.seed(2)

model.svmr2 = train(x = x.train,
                    y = y.train,
                  method = "svmRadialCost",
                  tuneGrid = data.frame(C = exp(seq(-8, 1, len = 20))),
                  trControl = ctrl)

model.svmr2$bestTune

ggplot(model.svmr2, highlight = TRUE, par.settings = myPar)

#  scaled model
set.seed(2)

scaled.model.svmr2 = train(x = x.train.scaled,
                    y = y.train.scaled,
                  method = "svmRadialCost",
                  tuneGrid = data.frame(C = exp(seq(-8, 1, len = 20))),
                  trControl = ctrl)

scaled.model.svmr2$bestTune

ggplot(scaled.model.svmr2, highlight = TRUE, par.settings = myPar)
```
\newpage

# Results

## Model Comparison: Cross Validation Performance
```{r}
res = resamples(list(GLM = model.glm,
                     GLMNET = model.glmn,
                     KNN = model.knn,
                     PLS = model.pls,
                     GAM = model.gam,
                     MARS = model.mars, 
                     LDA = model.lda, 
                     QDA = model.qda, 
                     NB = model.nb, 
                     CART = model.cart, 
                     CIT = model.cit,
                     RF = model.rf,
                     SVML = model.svml,
                     E1071 = model.svml2,
                     SVMR = model.svmr,
                     SVMR2 = model.svmr2,
                     gbmA = model.gbmA
                     ))
summary(res)

bwplot(res, metric = "ROC") # gbMA has highest median and mean ROC
                  
# Cross-validation error
glm.predict = predict(model.glm, newdata = x.train)
glmnet.predict = predict(model.glmn, newdata = x.train)
knn.predict = predict(model.knn, newdata = x.train)
pls.predict = predict(model.pls, newdata = x.train)
gam.predict = predict(model.gam, newdata = x.train)
mars.predict = predict(model.mars, newdata = x.train)
lda.predict = predict(model.lda, newdata = x.train)
qda.predict = predict(model.qda, newdata = x.train)
nb.predict = predict(model.nb, newdata = x.train)
cart.predict = predict(model.cart, newdata = x.train)
cit.predict = predict(model.cit, newdata = x.train)
rf.predict = predict(model.rf, newdata = x.train)
svml.predict = predict(model.svml, newdata = x.train)
e1071.predict = predict(model.svml2, newdata = x.train)
svmr.predict = predict(model.svmr, newdata = x.train)
svmr2.predict = predict(model.svmr2, newdata = x.train)
gbmA.predict = predict(model.gbmA, newdata = x.train)

confusionMatrix(data = glm.predict, reference = y.train)
confusionMatrix(data = glmnet.predict, reference = y.train)
confusionMatrix(data = knn.predict, reference = y.train)
confusionMatrix(data = pls.predict, reference = y.train)
confusionMatrix(data = gam.predict, reference = y.train)
confusionMatrix(data = mars.predict, reference = y.train)
confusionMatrix(data = lda.predict, reference = y.train)
confusionMatrix(data = qda.predict, reference = y.train)
confusionMatrix(data = nb.predict, reference = y.train)
confusionMatrix(data = cart.predict, reference = y.train)
confusionMatrix(data = cit.predict, reference = y.train)
confusionMatrix(data = rf.predict, reference = y.train)              
confusionMatrix(data = svml.predict, reference = y.train)  
confusionMatrix(data = e1071.predict, reference = y.train) 
confusionMatrix(data = svmr.predict, reference = y.train) 
confusionMatrix(data = svmr2.predict, reference = y.train) 
confusionMatrix(data = gbmA.predict, reference = y.train)

# 1 - accuracy
gbm_CV_error = 1 - 0.86
glmnet_CV_error = 1 - 0.825 
knn_CV_error = 1 - 0.7425
pls_CV_error = 1 - 0.8488 
gam_CV_error = 1 - 0.8688 
mars_CV_error = 1 - 0.8538
lda_CV_error = 1 - 0.845
qda_CV_error = 1 - 0.8662
nb_CV_error = 1 - 0.815
cart_CV_error = 1 - 0.895
cit_CV_error = 1 - 0.8688
rf_CV_error = 1 - 0.94
svml_CV_error = 1 - 0.8225
e1071_CV_error = 1 - 0.8612
svmr_CV_error = 1 - 0.87
svmr2_CV_error = 1 - 0.8712
gbMA_CV_error = 1 - 0.8888

# CV error
gbm_CV_error
glmnet_CV_error
knn_CV_error
pls_CV_error 
gam_CV_error
mars_CV_error
lda_CV_error
qda_CV_error
nb_CV_error
cart_CV_error
cit_CV_error
rf_CV_error
svml_CV_error
e1071_CV_error
svmr_CV_error
svmr2_CV_error
gbMA_CV_error
```
\newpage
The gbmA boosted model has the highest mean and median ROC value, based on the resampling summary. The random forest model, however, has the lowest cross-validation error, therefore is the model I choose. 

## Scaled Model Performance
```{r}
res2 = resamples(list(GLM = scaled.model.glm,
                     GLMNET = scaled.model.glmn,
                     KNN = scaled.model.knn,
                     PLS = scaled.model.pls,
                     GAM = scaled.model.gam,
                     MARS = scaled.model.mars, 
                     LDA = scaled.model.lda, 
                     QDA = scaled.model.qda, 
                     NB = scaled.model.nb, 
                     CART = scaled.model.cart, 
                     CIT = scaled.model.cit,
                     RF = scaled.model.rf,
                     SVML = scaled.model.svml,
                     E1071 = scaled.model.svml2,
                     SVMR = scaled.model.svmr,
                     SVMR2 = scaled.model.svmr2,
                     gbmA = scaled.model.gbmA
                     ))
summary(res2)

bwplot(res2, metric = "ROC")
```

## Test Data Performance
```{r}
# test error: gbmA
gbMA.test = predict(model.gbmA, newdata = x.test)

confusionMatrix(data = gbMA.test,
                reference = y.test,
                )
# 1 - accuracy
gbmA_test_error = 1 - 0.865
gbmA_test_error

# test error: random forest
rf.test = predict(model.rf, newdata = x.test)

confusionMatrix(data = rf.test,
                reference = y.test,
                )
# 1 - accuracy
rf_test_error = 1 - 0.855
rf_test_error
```